{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Text Analytics & Applications\n",
    "\n",
    "## Learning Objectives\n",
    "* Understand and apply Natural Language Processing concepts\n",
    "* Create effective text visualisations\n",
    "* Perform sentiment analysis on real text data\n",
    "* Build practical text analytics solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Natural Language Processing Concepts\n",
    "\n",
    "Let's set up our environment with the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt nltk spacy textblob wordcloud\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('words')\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "print(\"Environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Part-of-Speech Tagging\n",
    "\n",
    "POS tagging helps identify the role of each word in a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_pos(text):\n",
    "    # Tokenise and tag\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged = pos_tag(tokens)\n",
    "\n",
    "    # Create readable output\n",
    "    pos_dict = {\n",
    "        'NNP': 'Proper Noun',\n",
    "        'NN': 'Noun',\n",
    "        'VB': 'Verb',\n",
    "        'JJ': 'Adjective',\n",
    "        'RB': 'Adverb'\n",
    "    }\n",
    "\n",
    "    return [(word, pos_dict.get(tag[:2], tag)) for word, tag in tagged]\n",
    "\n",
    "# Example text\n",
    "text = \"Data Science helps companies make better decisions quickly.\"\n",
    "\n",
    "pos_results = analyse_pos(text)\n",
    "print(\"Part of Speech Analysis:\")\n",
    "for word, pos in pos_results:\n",
    "    print(f\"{word}: {pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Named Entity Recognition (NER)\n",
    "\n",
    "NER identifies entities like names, organisations, and locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    # Process with spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract entities\n",
    "    entities = {\n",
    "        'ORG': [],\n",
    "        'PERSON': [],\n",
    "        'DATE': [],\n",
    "        'GPE': []  # Geographical/Political Entities\n",
    "    }\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in entities:\n",
    "            entities[ent.label_].append(ent.text)\n",
    "\n",
    "    return entities\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"Microsoft announced new AI features in February 2024.\n",
    "Sarah Johnson from Google presented at the London conference.\"\"\"\n",
    "\n",
    "entities = extract_entities(text)\n",
    "print(\"Named Entities Found:\")\n",
    "for entity_type, items in entities.items():\n",
    "    if items:\n",
    "        print(f\"{entity_type}: {', '.join(items)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Text Visualisation \n",
    "\n",
    "### 2.1 Word Clouds\n",
    "\n",
    "Word clouds provide a visual representation of word frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordcloud(text):\n",
    "    wordcloud = WordCloud(width=800, height=400,\n",
    "                         background_color='white',\n",
    "                         min_font_size=10).generate(text)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example text - multiple customer reviews\n",
    "reviews = \"\"\"\n",
    "Great data visualisation tool! Really helps with analysis.\n",
    "The machine learning features are impressive.\n",
    "Data analysis has never been easier.\n",
    "Excellent visualisation capabilities and machine learning support.\n",
    "Great for data science projects and analysis tasks.\n",
    "\"\"\"\n",
    "\n",
    "create_wordcloud(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sentiment Distribution\n",
    "\n",
    "Visualising sentiment across multiple texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import seaborn as sns\n",
    "\n",
    "def analyse_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Example reviews\n",
    "reviews = [\n",
    "    \"Excellent product, very satisfied!\",\n",
    "    \"Not what I expected, disappointed.\",\n",
    "    \"Good features but expensive.\",\n",
    "    \"Amazing customer service!\",\n",
    "    \"Needs improvement.\"\n",
    "]\n",
    "\n",
    "# Calculate sentiments\n",
    "sentiments = [analyse_sentiment(review) for review in reviews]\n",
    "\n",
    "# Create distribution plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(sentiments, bins=20)\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Print average sentiment\n",
    "print(f\"Average sentiment: {sum(sentiments)/len(sentiments):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Applied Exercise - Customer Feedback Analysis \n",
    "\n",
    "Let's build a complete analysis pipeline for customer feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackAnalyser:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    def analyse_feedback(self, feedback):\n",
    "        # Basic metrics\n",
    "        doc = self.nlp(feedback)\n",
    "        word_count = len([token for token in doc if not token.is_punct])\n",
    "\n",
    "        # Sentiment\n",
    "        sentiment = TextBlob(feedback).sentiment.polarity\n",
    "\n",
    "        # Key entities\n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "        # Key phrases (noun chunks)\n",
    "        key_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "\n",
    "        return {\n",
    "            'word_count': word_count,\n",
    "            'sentiment': sentiment,\n",
    "            'entities': entities,\n",
    "            'key_phrases': key_phrases\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "analyser = FeedbackAnalyser()\n",
    "\n",
    "feedback = \"\"\"\n",
    "The new Data Science Pro software from TechCorp has transformed our analytics capabilities.\n",
    "The machine learning features are impressive, though the visualisation tools need improvement.\n",
    "Sarah from customer support was very helpful with the installation process.\n",
    "\"\"\"\n",
    "\n",
    "results = analyser.analyse_feedback(feedback)\n",
    "\n",
    "print(\"Feedback Analysis Results:\")\n",
    "print(f\"Word Count: {results['word_count']}\")\n",
    "print(f\"Sentiment Score: {results['sentiment']:.2f}\")\n",
    "print(\"\\nIdentified Entities:\")\n",
    "for entity, label in results['entities']:\n",
    "    print(f\"- {entity}: {label}\")\n",
    "print(\"\\nKey Phrases:\")\n",
    "for phrase in results['key_phrases']:\n",
    "    print(f\"- {phrase}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn!\n",
    "\n",
    "Try analyzing some text from your organisation using the FeedbackAnalyser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "your_feedback = \"\"\"\n",
    "Replace this with your own text from customer feedback,\n",
    "product documentation, or internal communications\n",
    "\"\"\"\n",
    "\n",
    "your_results = analyser.analyse_feedback(your_feedback)\n",
    "\n",
    "# Analyze and visualize the results\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this session, we've covered:\n",
    "1. Advanced NLP concepts:\n",
    "   - Part-of-speech tagging\n",
    "   - Named Entity Recognition\n",
    "2. Text visualisation techniques:\n",
    "   - Word clouds\n",
    "   - Sentiment distribution\n",
    "3. Practical application with customer feedback analysis\n",
    "\n",
    "### Next Steps\n",
    "- Explore more advanced NLP techniques\n",
    "- Try different visualisation libraries\n",
    "- Apply these techniques to your own projects\n",
    "\n",
    "### Additional Resources\n",
    "- [spaCy Documentation](https://spacy.io/)\n",
    "- [TextBlob Documentation](https://textblob.readthedocs.io/)\n",
    "- [Seaborn Visualisation Guide](https://seaborn.pydata.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
